{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì‹œê°í™” (Model Visualization)\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ë‚´ìš©:**\n",
    "- ë³µì› ê²°ê³¼ ë¹„êµ\n",
    "- ì—´í™” í‘œí˜„ (z_d) t-SNE ì‹œê°í™”\n",
    "- ì½˜í…ì¸  í‘œí˜„ (z_c) ë¶„ì„\n",
    "- Cross-domain transfer ê²°ê³¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from src.models import CrossDomainDegradationTransfer\n",
    "from src.data.datasets import get_dataset\n",
    "from src.data.loader import get_default_transform\n",
    "from src.utils.metrics import compute_psnr, compute_ssim\n",
    "from src.utils.visualization import plot_tsne, plot_restoration_comparison\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ì„¤ì •\n",
    "CHECKPOINT_PATH = Path('../experiments/best.pth')  # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ\n",
    "DATA_ROOT = Path('../data')\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path, device):\n",
    "    \"\"\"ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    model = CrossDomainDegradationTransfer().to(device)\n",
    "    \n",
    "    if checkpoint_path.exists():\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {checkpoint_path}\")\n",
    "        if 'epoch' in checkpoint:\n",
    "            print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "    else:\n",
    "        print(f\"ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì´ˆê¸°í™” ëª¨ë¸ ì‚¬ìš©.\")\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model(CHECKPOINT_PATH, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë³µì› ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_restoration(model, dataset, n_samples=4, device='cpu'):\n",
    "    \"\"\"ë³µì› ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    n_samples = min(n_samples, len(dataset))\n",
    "    indices = np.random.choice(len(dataset), n_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, n_samples, figsize=(4*n_samples, 12))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        item = dataset[idx]\n",
    "        degraded = item['degraded'].unsqueeze(0).to(device)\n",
    "        clean = item['clean']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(degraded)\n",
    "            restored = outputs['restored'].squeeze(0).cpu()\n",
    "        \n",
    "        # [-1, 1] -> [0, 1]\n",
    "        degraded_np = (item['degraded'].permute(1, 2, 0).numpy() * 0.5 + 0.5).clip(0, 1)\n",
    "        restored_np = (restored.permute(1, 2, 0).numpy() * 0.5 + 0.5).clip(0, 1)\n",
    "        clean_np = (clean.permute(1, 2, 0).numpy() * 0.5 + 0.5).clip(0, 1)\n",
    "        \n",
    "        # PSNR/SSIM ê³„ì‚°\n",
    "        psnr = compute_psnr(\n",
    "            (restored + 1) / 2,\n",
    "            (clean + 1) / 2\n",
    "        ).item()\n",
    "        ssim = compute_ssim(\n",
    "            ((restored + 1) / 2).unsqueeze(0),\n",
    "            ((clean + 1) / 2).unsqueeze(0)\n",
    "        ).item()\n",
    "        \n",
    "        axes[0, i].imshow(degraded_np)\n",
    "        axes[0, i].set_title('Degraded')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        axes[1, i].imshow(restored_np)\n",
    "        axes[1, i].set_title(f'Restored\\nPSNR: {psnr:.2f} | SSIM: {ssim:.3f}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        axes[2, i].imshow(clean_np)\n",
    "        axes[2, i].set_title('Ground Truth')\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ ë° ì‹œê°í™”\n",
    "transform = get_default_transform(image_size=256, train=False)\n",
    "\n",
    "# ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "for domain in ['imagenet', 'ldct', 'dibco', 'fmd']:\n",
    "    path = DATA_ROOT / domain if domain != 'imagenet' else DATA_ROOT / 'imagenet-c'\n",
    "    if path.exists():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ğŸ“· {domain.upper()} ë³µì› ê²°ê³¼\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        dataset = get_dataset(domain, str(path), transform=transform)\n",
    "        if len(dataset) > 0:\n",
    "            visualize_restoration(model, dataset, n_samples=4, device=device)\n",
    "        break\n",
    "else:\n",
    "    print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì—´í™” í‘œí˜„ (z_d) t-SNE ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_degradation_features(model, datasets, n_samples_per_domain=100, device='cpu'):\n",
    "    \"\"\"ê° ë„ë©”ì¸ì—ì„œ ì—´í™” í‘œí˜„ ì¶”ì¶œ\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for domain_idx, (name, dataset) in enumerate(datasets.items()):\n",
    "        if len(dataset) == 0:\n",
    "            continue\n",
    "        \n",
    "        n = min(n_samples_per_domain, len(dataset))\n",
    "        indices = np.random.choice(len(dataset), n, replace=False)\n",
    "        \n",
    "        for idx in indices:\n",
    "            item = dataset[idx]\n",
    "            degraded = item['degraded'].unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                z_d, _ = model.encode_degradation(degraded)\n",
    "            \n",
    "            all_features.append(z_d.cpu().numpy().flatten())\n",
    "            all_labels.append(name)\n",
    "    \n",
    "    return np.array(all_features), all_labels\n",
    "\n",
    "\n",
    "def plot_tsne_visualization(features, labels, title=\"t-SNE of Degradation Representations\"):\n",
    "    \"\"\"t-SNE ì‹œê°í™”\"\"\"\n",
    "    from sklearn.manifold import TSNE\n",
    "    \n",
    "    # t-SNE ì ìš©\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features)-1))\n",
    "    features_2d = tsne.fit_transform(features)\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    unique_labels = list(set(labels))\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for label, color in zip(unique_labels, colors):\n",
    "        mask = [l == label for l in labels]\n",
    "        plt.scatter(\n",
    "            features_2d[mask, 0],\n",
    "            features_2d[mask, 1],\n",
    "            c=[color],\n",
    "            label=label.upper(),\n",
    "            alpha=0.7,\n",
    "            s=50\n",
    "        )\n",
    "    \n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ë„ë©”ì¸ì˜ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "datasets = {}\n",
    "transform = get_default_transform(image_size=256, train=False)\n",
    "\n",
    "domain_paths = {\n",
    "    'imagenet': DATA_ROOT / 'imagenet-c',\n",
    "    'ldct': DATA_ROOT / 'ldct',\n",
    "    'dibco': DATA_ROOT / 'dibco',\n",
    "    'fmd': DATA_ROOT / 'fmd',\n",
    "}\n",
    "\n",
    "for name, path in domain_paths.items():\n",
    "    if path.exists():\n",
    "        ds = get_dataset(name, str(path), transform=transform)\n",
    "        if len(ds) > 0:\n",
    "            datasets[name] = ds\n",
    "            print(f\"{name}: {len(ds)} samples\")\n",
    "\n",
    "if len(datasets) >= 2:\n",
    "    print(\"\\nì—´í™” í‘œí˜„ ì¶”ì¶œ ì¤‘...\")\n",
    "    features, labels = extract_degradation_features(model, datasets, n_samples_per_domain=50, device=device)\n",
    "    print(f\"ì´ {len(features)} ìƒ˜í”Œ ì¶”ì¶œ ì™„ë£Œ\")\n",
    "    \n",
    "    plot_tsne_visualization(features, labels)\n",
    "else:\n",
    "    print(\"t-SNE ì‹œê°í™”ë¥¼ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ë„ë©”ì¸ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Domain Transfer ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_transfer(model, source_dataset, target_dataset, device='cpu'):\n",
    "    \"\"\"Cross-domain transfer ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    if len(source_dataset) == 0 or len(target_dataset) == 0:\n",
    "        print(\"ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ëœë¤ ìƒ˜í”Œ ì„ íƒ\n",
    "    source_idx = np.random.randint(len(source_dataset))\n",
    "    target_idx = np.random.randint(len(target_dataset))\n",
    "    \n",
    "    source_item = source_dataset[source_idx]\n",
    "    target_item = target_dataset[target_idx]\n",
    "    \n",
    "    source_img = source_item['degraded'].unsqueeze(0).to(device)\n",
    "    target_img = target_item['degraded'].unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Source ë³µì›\n",
    "        source_restored = model.restore(source_img).squeeze(0).cpu()\n",
    "        # Target ë³µì›\n",
    "        target_restored = model.restore(target_img).squeeze(0).cpu()\n",
    "        # ì—´í™” ì „ì´: sourceì˜ ì—´í™”ë¥¼ targetì— ì ìš©\n",
    "        transferred = model.transfer_degradation(source_img, target_img).squeeze(0).cpu()\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    \n",
    "    def to_numpy(x):\n",
    "        return (x.permute(1, 2, 0).numpy() * 0.5 + 0.5).clip(0, 1)\n",
    "    \n",
    "    # Source row\n",
    "    axes[0, 0].imshow(to_numpy(source_item['degraded']))\n",
    "    axes[0, 0].set_title('Source (Degraded)')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(to_numpy(source_restored))\n",
    "    axes[0, 1].set_title('Source Restored')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[0, 2].imshow(to_numpy(source_item['clean']))\n",
    "    axes[0, 2].set_title('Source GT')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # Target row\n",
    "    axes[1, 0].imshow(to_numpy(target_item['degraded']))\n",
    "    axes[1, 0].set_title('Target (Degraded)')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(to_numpy(target_restored))\n",
    "    axes[1, 1].set_title('Target Restored')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    axes[1, 2].imshow(to_numpy(transferred))\n",
    "    axes[1, 2].set_title('Transfer: Sourceâ†’Target')\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle('Cross-Domain Degradation Transfer', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-domain transfer ì‹œê°í™”\n",
    "if len(datasets) >= 2:\n",
    "    domain_names = list(datasets.keys())\n",
    "    source_name, target_name = domain_names[0], domain_names[1]\n",
    "    \n",
    "    print(f\"Transfer: {source_name.upper()} â†’ {target_name.upper()}\")\n",
    "    visualize_transfer(model, datasets[source_name], datasets[target_name], device=device)\n",
    "else:\n",
    "    print(\"Cross-domain transferë¥¼ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ë„ë©”ì¸ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë©”íŠ¸ë¦­ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_domain(model, dataset, n_samples=50, device='cpu'):\n",
    "    \"\"\"ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ ê³„ì‚°\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        return None\n",
    "    \n",
    "    n = min(n_samples, len(dataset))\n",
    "    indices = np.random.choice(len(dataset), n, replace=False)\n",
    "    \n",
    "    psnrs, ssims = [], []\n",
    "    \n",
    "    for idx in indices:\n",
    "        item = dataset[idx]\n",
    "        degraded = item['degraded'].unsqueeze(0).to(device)\n",
    "        clean = item['clean'].unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            restored = model.restore(degraded)\n",
    "        \n",
    "        # [0, 1] ë²”ìœ„ë¡œ ë³€í™˜\n",
    "        restored_01 = (restored + 1) / 2\n",
    "        clean_01 = (clean + 1) / 2\n",
    "        \n",
    "        psnrs.append(compute_psnr(restored_01, clean_01).item())\n",
    "        ssims.append(compute_ssim(restored_01, clean_01).item())\n",
    "    \n",
    "    return {\n",
    "        'psnr_mean': np.mean(psnrs),\n",
    "        'psnr_std': np.std(psnrs),\n",
    "        'ssim_mean': np.mean(ssims),\n",
    "        'ssim_std': np.std(ssims),\n",
    "    }\n",
    "\n",
    "# ëª¨ë“  ë„ë©”ì¸ í‰ê°€\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë„ë©”ì¸ë³„ ì„±ëŠ¥ ìš”ì•½\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Domain':<12} {'PSNR':<20} {'SSIM':<20}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "    metrics = evaluate_domain(model, dataset, n_samples=30, device=device)\n",
    "    if metrics:\n",
    "        print(f\"{name.upper():<12} {metrics['psnr_mean']:.2f} Â± {metrics['psnr_std']:.2f}       {metrics['ssim_mean']:.4f} Â± {metrics['ssim_std']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
